{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Predicting Storm Surge in Venice\n",
    "\n",
    "### Goal\n",
    "\n",
    "Predict water level of the next 24h\n",
    "\n",
    "\n",
    "![stations](MSLP_stations.png)\n",
    "\n",
    "\n",
    "### Training Data\n",
    "\n",
    "* Simulated mean sea level pressure (MSLP)\n",
    "* Measured wind speed and direction\n",
    "* Measured water level\n",
    "\n",
    "One FNN example consists of:\n",
    "\n",
    "1. The simulated MSLP values previous 24h + current MSLP + next 24h sampled every 3h\n",
    "\n",
    "```\n",
    "14 stations * (8 + 8 + 1) = 238\n",
    "```\n",
    "\n",
    "2. Wind speed and direction at PI station 10h (1 hourly) + current values\n",
    "\n",
    "```    \n",
    "2 measurements * (10 + 1) = 22\n",
    "```\n",
    "\n",
    "3. Water level (surge only) previous 50h (1 hourly) + current value\n",
    "\n",
    "```\n",
    "1 measurement * (50 + 1) = 51\n",
    "```\n",
    "\n",
    "Which makes a total of 311 features per example.\n",
    "\n",
    "\n",
    "### PyTorch Concepts\n",
    "\n",
    "* Datasets\n",
    "* Dataloaders\n",
    "* Samplers\n",
    "* Networks\n",
    "* Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class HDF5Dataset(Dataset):\n",
    "    \"\"\"Read HDF5 files from a directory\"\"\"\n",
    "\n",
    "    def __init__(self, directory):\n",
    "        self.directory = pathlib.Path(directory)\n",
    "        self.files = list(self.directory.glob(\"*.hdf5\"))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        with h5py.File(self.files[index], \"r\") as src:\n",
    "            inputs = src[\"inputs\"][:]\n",
    "            labels = src[\"labels\"][:]\n",
    "        return inputs, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HDF5Dataset('../../exchange/venice/all_data/devel_data/test')\n",
    "for _ in range(5):\n",
    "    idx = np.random.randint(low=0, high=len(dataset))\n",
    "    inputs, labels = dataset[idx]\n",
    "    plt.plot(labels)\n",
    "plt.show()\n",
    "print(f\"Inputs shape: {inputs.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = iter(DataLoader(dataset, batch_size=5, shuffle=True, num_workers=1))\n",
    "inputs, labels = next(loader)\n",
    "for y in labels:\n",
    "    plt.plot(y.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samplers\n",
    "\n",
    "A very convenient way of controlling the statistics of your mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler\n",
    "\n",
    "class ExtremeRandomSampler(Sampler):\n",
    "    \"\"\"Sample a random extreme event with a given probability\"\"\"\n",
    "\n",
    "    def __init__(self, dataset, num_samples=None, extreme_height=0.4, extreme_probability=0.5):\n",
    "        self.dataset = dataset\n",
    "        self.num_samples = len(dataset) if num_samples is None else num_samples\n",
    "        self.extreme_height = extreme_height\n",
    "        self.extreme_probability = extreme_probability\n",
    "        self.prob = [extreme_probability, 1 - extreme_probability]\n",
    "        self.length = len(dataset)\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = []\n",
    "        for _ in range(self.num_samples):\n",
    "            extreme = np.random.choice([False, True], p=self.prob)\n",
    "            idx = np.random.randint(low=0, high=self.length)\n",
    "\n",
    "            while not extreme:\n",
    "                _, labels = self.dataset[idx]\n",
    "                if np.any(labels > self.extreme_height):\n",
    "                    extreme = True\n",
    "                else:\n",
    "                    idx = np.random.randint(low=0, high=self.length)\n",
    "            indices.append(idx)\n",
    "        return iter(indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "sampler = ExtremeRandomSampler(\n",
    "    dataset,\n",
    "    num_samples=5,\n",
    "    extreme_probability=1.,\n",
    "    extreme_height=0.4)\n",
    "\n",
    "loader = iter(DataLoader(dataset, batch_size=5, sampler=sampler))\n",
    "inputs, labels = next(loader)\n",
    "for y in labels:\n",
    "    plt.plot(y.numpy())\n",
    "\n",
    "length = y.size(0)\n",
    "plt.plot(np.arange(length), np.zeros(length)+0.4, '-.', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1000\n",
    "INPUT_SIZE = 311\n",
    "OUTPUT_SIZE = 24\n",
    "HIDDEN_SIZE = 1024\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "N_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_ds = HDF5Dataset('../../exchange/venice/all_data/devel_data/test')\n",
    "val_ds = HDF5Dataset('../../exchange/venice/all_data/devel_data/test')\n",
    "\n",
    "# with or without sampler\n",
    "sampler = ExtremeRandomSampler(\n",
    "    dataset, extreme_height=0.4, extreme_probability=0.01)\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    "    # sampler=sampler\n",
    ")\n",
    "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = FNN(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Loop - Manually\n",
    "\n",
    "A higher level tool for training loops is for example [ignite](https://pytorch.org/ignite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}/{N_EPOCHS}\")\n",
    "    \n",
    "    # Train\n",
    "    model.train()  # IMPORTANT: some models have train/eval specific behavior\n",
    "    \n",
    "    running_loss, correct = 0.0, 0\n",
    "    for X, y in train_dl:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # with torch.set_grad_enabled(True):\n",
    "        y_ = model(X)\n",
    "        loss = criterion(y_, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        print(f\"    batch loss: {loss.item():0.3f}\")\n",
    "        running_loss += loss.item() * X.shape[0]\n",
    "\n",
    "    print(f\"  Train Loss: {running_loss / len(train_dl.dataset)}\")\n",
    "\n",
    "\n",
    "    # Eval\n",
    "    model.eval()  # IMPORTANT\n",
    "\n",
    "    running_loss, correct = 0.0, 0\n",
    "    with torch.no_grad():  # IMPORTANT\n",
    "        for X, y in val_dl:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            y_ = model(X)\n",
    "\n",
    "            loss = criterion(y_, y)\n",
    "            running_loss += loss.item() * X.shape[0]\n",
    "\n",
    "    print(f\"  Valid Loss: {running_loss / len(val_dl.dataset)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results!\n",
    "\n",
    "![performance](https://raw.githubusercontent.com/DHI/venice-predict/master/images/performance.png?token=AcLu2dIwONN3tLNTNcn3iB5JcnY4McW1ks5cStxewA%3D%3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you!\n",
    "\n",
    "Some further links:\n",
    "\n",
    "* Talk by [Stefan Sotte](https://github.com/sotte/pytorch_tutorial)\n",
    "* Transfer Learning [Tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
    "* Use all of Tensorboards visualization features via [tensorboardX](https://github.com/lanpa/tensorboardX)!\n",
    "* [torchvision](https://pytorch.org/docs/stable/torchvision/index.html) for transforms, pre-trained models, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
